{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary imports\n",
    "\n",
    "import os # For file operations\n",
    "import collections # For counting characters in files and creating a dictionary\n",
    "import random # For selecting random items from lists\n",
    "import json # For exporting model as a JSON file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Third-Order Letter Approximation Model\n",
    "## Step 1: Create method to format text files\n",
    "\n",
    "The `formatFiles` method is used to process text files in a folder to count how often certain characters appear. The [Counter() function](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) in Python's 'collections' module is used to keep track of character counts across all files. It then goes through each file in the folder using the [listdir() function in the 'os' module](https://pytutorial.com/python-using-oslistdir-to-list-files-in-a-directory/), checking if it ends with .txt and joining the file name and the directory path together using another function from the 'os' module, [path.join()](https://www.geeksforgeeks.org/python-os-path-join-method/), in order to access the file via the file path.\n",
    "\n",
    "For each text file, it reads the content using UTF-8 encoding and converts everything to uppercase. It removes any characters not in the list and searches for specific start and end markers to extract the main content of the file, using both [find()](https://www.w3schools.com/python/ref_string_find.asp) and Python's [slicing function](https://www.w3schools.com/python/ref_func_slice.asp). If these markers are found, it keeps only the text between them. It counts the characters in this cleaned text using the Counter() function and adds these counts to the total. Finally, it prints out the total counts for each character and returns the cleaned files in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the text files\n",
    "directory = r'..\\docs\\utf8_english_works'\n",
    "\n",
    "# The characters to keep (ASCII, full stops, spaces).\n",
    "keep = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ .'\n",
    "\n",
    "# Initialize a Counter to store the frequency of each character across all files\n",
    "totalCounts = collections.Counter()\n",
    "    \n",
    "# Initialize a list to store cleaned files\n",
    "cleanedFiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all files in the directory\n",
    "for fileName in os.listdir(directory):\n",
    "    if fileName.endswith('.txt'):\n",
    "        filePath = os.path.join(directory, fileName)\n",
    "            \n",
    "        # Open the file with UTF-8 encoding\n",
    "        with open(filePath, 'r', encoding='utf-8') as file:\n",
    "            # Read the whole file into a string.\n",
    "            english = file.read()\n",
    "\n",
    "            # Change everything to upper case.\n",
    "            english = english.upper()\n",
    "\n",
    "            # Remove unwanted characters.\n",
    "            cleaned = ''.join(c for c in english if c in keep)\n",
    "\n",
    "            # Append the cleaned file to the list of cleaned files\n",
    "            cleanedFiles.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each character\n",
    "for cleaned in cleanedFiles:\n",
    "    # Remove preamble and postamble.If find returns -1, the substring was not found.\n",
    "    start = cleaned.find('START OF THE PROJECT GUTENBERG EBOOK')\n",
    "    end = cleaned.find('END OF THE PROJECT GUTENBERG EBOOK')\n",
    "\n",
    "    # If the substrings are found, extract the main content.\n",
    "    if start != -1 and end != -1:\n",
    "        cleaned = cleaned[start:end]\n",
    "    else:\n",
    "        print(\"ERROR: Substrings not found in file:\", fileName)\n",
    "        \n",
    "    # Count the frequency of each character in the current file\n",
    "    counts = collections.Counter(cleaned)\n",
    "\n",
    "    # Update the total counts with the counts from the current file\n",
    "    totalCounts.update(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'S': 136438\n",
      "'T': 193301\n",
      "'A': 171189\n",
      "'R': 122258\n",
      "' ': 442809\n",
      "'O': 159367\n",
      "'F': 46913\n",
      "'H': 136849\n",
      "'E': 265142\n",
      "'P': 36138\n",
      "'J': 2418\n",
      "'C': 49677\n",
      "'G': 43500\n",
      "'U': 60490\n",
      "'N': 147529\n",
      "'B': 33311\n",
      "'K': 16941\n",
      "'L': 87108\n",
      "'Y': 42416\n",
      "'I': 144493\n",
      "'M': 55608\n",
      "'D': 92967\n",
      "'W': 50034\n",
      "'.': 23533\n",
      "'V': 19577\n",
      "'X': 2706\n",
      "'Z': 1117\n",
      "'Q': 2769\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for char, count in totalCounts.items():\n",
    "    print(f\"'{char}': {count}\")\n",
    "\n",
    "# Store contents of cleaned files in a list in order to count the number of sequences later\n",
    "cleanedList = cleanedFiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process Text Files\n",
    "\n",
    "The `formatFiles` method's functionality is tested by passing through both the directory containing all the text files and a string containing all the characters to keep. All text files in the folder are processed, while keeping the characters A-Z, space, and period. After the `formatFiles` method is called and takes the specified directory and characters to keep as arguments, it then reads and formats the text files, and counts the frequency of each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Method to Create Trigram Model\n",
    "The method `countTrigrams` is created which takes in the previously created list of cleaned texts as an argument. Using the [defaultdict()](https://www.geeksforgeeks.org/defaultdict-in-python/) function, it initializes a dictionary as the data structure to store the results; this is effective because dictionaries in Python use key-value pairs, which is perfect for storing each trigram as a key and its respective appearance count as a value.\n",
    "\n",
    "This method then iterates over each cleaned text and extracts the trigrams by slicing the text from a particular index range using the [range()](https://www.w3schools.com/python/ref_func_range.asp)\n",
    " function, incrementing the count of each trigram in the dictionary as it goes. The total count for each trigram is arranged from highest to lowest using the [sorted()](https://www.w3schools.com/python/ref_func_sorted.asp) function. The final result is a sorted dictionary that holds the contents of the trigram model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' TH', 50120), ('THE', 42657), ('HE ', 33535), ('ED ', 19427), ('AND', 19167), ('ND ', 18886), (' AN', 18522), ('ING', 16298), (' OF', 15054), ('NG ', 14348), (' TO', 14170), ('OF ', 13953), ('TO ', 12595), ('ER ', 12564), (' IN', 12352), ('AT ', 12066), ('IS ', 11072), ('IN ', 10547), (' HE', 10223), ('RE ', 9472)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the trigram counts \n",
    "trigramCounts = collections.defaultdict(int) \n",
    "\n",
    "# Iterate over each cleaned file's content\n",
    "for cleaned in cleanedList:\n",
    "    # Iterate over the cleaned text to extract trigrams \n",
    "    for i in range(len(cleaned)): \n",
    "        trigram = cleaned[i:i+3] # Creates trigram by slicing the cleaned text from index i to i+3\n",
    "        trigramCounts[trigram] += 1 # Increment the count of the trigram in the dictionary\n",
    "\n",
    "    # Sort the trigram counts from highest to lowest\n",
    "    trigramModel = sorted(trigramCounts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Only displays the top 20 trigrams for brevity\n",
    "print(trigramModel[:20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Pass Through Data and Create Trigram Model\n",
    "\n",
    "The `countTrigrams` method is tested by passing through textToCount, the list that was previously generated with all the cleaned text files. The data in the list is processed and used to create a trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Third Order Letter Approximation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Method to Initialize String beginning with TH\n",
    "Here the `initializeString` method is used to initialize a string beginning with TH, which will later be extended up to 10,000 characters. Trigrams beginning with TH and weights are found/created using [list comprehension](https://chatgpt.com/share/670583e8-8ca0-800f-bddd-9e8e27b62db1), with the weights being based off each trigram's reoccurence in the model. Both the trigrams beginning with TH along with their odds of being picked are then displayed using the [zip()](https://www.geeksforgeeks.org/zip-in-python/) function to merge the corresponding lists of trigrams and weights.\n",
    "\n",
    "A trigram is then picked at random using the [random.choices()](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) function, [which bases its selection off weights](https://pynative.com/python-weighted-random-choices-with-probability/); with the more reoccuring trigrams having a higher chance of being selected such as 'THE', 'THA' etc. Using the [str()](https://www.w3schools.com/python/ref_func_str.asp)\n",
    " function the chosen trigram is converted to a string and is returned by the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams: | Odds of being chosen:\n",
      "THE       | 42657/67788\n",
      "THA       | 8266/67788\n",
      "TH        | 5632/67788\n",
      "THI       | 5589/67788\n",
      "THO       | 2667/67788\n",
      "THR       | 1349/67788\n",
      "THU       | 353/67788\n",
      "THY       | 279/67788\n",
      "THS       | 254/67788\n",
      "TH.       | 214/67788\n",
      "THT       | 100/67788\n",
      "THL       | 74/67788\n",
      "THW       | 65/67788\n",
      "THF       | 57/67788\n",
      "THD       | 51/67788\n",
      "THH       | 50/67788\n",
      "THM       | 33/67788\n",
      "THP       | 23/67788\n",
      "THC       | 18/67788\n",
      "THN       | 13/67788\n",
      "THB       | 12/67788\n",
      "THQ       | 12/67788\n",
      "THG       | 10/67788\n",
      "THK       | 5/67788\n",
      "THJ       | 3/67788\n",
      "THV       | 2/67788\n"
     ]
    }
   ],
   "source": [
    "# Use list comprehension to find trigrams that start with 'TH'\n",
    "thKeys = [key for key, value in trigramModel if key.startswith('TH')]\n",
    "\n",
    "# Create weights based on reoccurrence of trigrams in the model\n",
    "weights = [value for key, value in trigramModel if key in thKeys]\n",
    "\n",
    "# Calculate the total weight\n",
    "totalWeight = sum(weights)\n",
    "\n",
    "# Print trigrams and weights alongside each other as key-value pairs with total weight as denominator\n",
    "print(\"Trigrams: | Odds of being chosen:\")\n",
    "for key, weight in zip(thKeys, weights):\n",
    "    print(f\"{key}       | {weight}/{totalWeight}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extracting Trigrams from Model and Initializing String\n",
    "In order to test the functionality of the initializeString method, the trigram model from Task 1 is passed through as an argument, in order to create a string beginning with \"TH\" and a third character that is chosen using probability which is based off its reoccurence in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen trigram to begin the string: THE\n"
     ]
    }
   ],
   "source": [
    "# Pick a trigram based on the weights, using [0] to extract the first element of the list \n",
    "chosenTrigram = random.choices(thKeys, weights)[0]\n",
    "\n",
    "# Convert the randomly chosen trigram to a string\n",
    "chosenTrigram = str(chosenTrigram)\n",
    "\n",
    "# Print the beginning of the 10,000 character string\n",
    "print(\"Chosen trigram to begin the string:\", chosenTrigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate More Characters to Add to the String\n",
    "In order to extend the string up to 10,000 characters, whilst adding new letters that are chosen based off weighted probability, a new method called `generateCharacters` is created. This method employs a lot of similar techniques to the `initializeString` method such as using list comprehension to find certain values and create weights.\n",
    "\n",
    " It uses Python's [string slicing](https://pythonexamples.org/python-string-get-last-n-characters/) function in order to get the last two characters of the string, finds trigrams in the model that begin with these two characters and randomly selects one of the third letters of those trigrams based off their weights by using the [random.choices()](https://www.w3schools.com/python/ref_random_choices.asp) function. For each third letter that is selected, it is added to the string until it reaches 10,000 characters. Once the string reaches 10,000 characters it is returned by the method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generated string with the chosen trigram\n",
    "generatedString = chosenTrigram\n",
    "\n",
    "# Loop until the string reaches the desired length (10,000 characters)\n",
    "while len(generatedString) < 10000:\n",
    "    # Get the last two characters of the current generated string\n",
    "    lastTwoChars = generatedString[-2:]\n",
    "        \n",
    "    # Use list comprehension to find trigams that start with the last two characters\n",
    "    possibleTrigrams = [key for key, value in trigramModel if key.startswith(lastTwoChars)]\n",
    "        \n",
    "    # Create weights based on reoccurrence of trigrams in the model\n",
    "    weights = [value for key, value in trigramModel if key in possibleTrigrams]\n",
    "        \n",
    "    # Pick a trigram based on the weights\n",
    "    chosenTrigram = random.choices(possibleTrigrams, weights)[0]\n",
    "        \n",
    "    # Add the third character of the chosen trigram to the generated string\n",
    "    generatedString += chosenTrigram[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Characters to String using Model and Initial String\n",
    "To see if the `generateCharacters` function will successfully create a 10,000 character string, it is tested by taking the trigram model created in Task 1 and the initial string generated in step 2 as arguments and uses them to create the final string. The final string is then partially printed to check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Generated String (first 100 characters): THEAS WILASH THEAS YED TH THALMON GE REAS MORRY ING     VE THE AS IN REENTEAS ANCLONTROBJECESSPE INT\n"
     ]
    }
   ],
   "source": [
    "# Ensure the generated string is exactly 10,000 characters long\n",
    "if len(generatedString) == 10000:\n",
    "    # Print the first 100 characters for verification\n",
    "    print(\"Final Generated String (first 100 characters):\", generatedString[:100])\n",
    "else:\n",
    "    # Return the generated string with an error message\n",
    "    print(\"ERROR: The generated string is not 10,000 characters, it is only\", len(generatedString), \"characters long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Analyze Your Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Method to Calculate English Word Percentage\n",
    "The `wordPercentage` method calculates the percentage of valid English words in the 10,000 character string. It reads the list of all English words from words.txt and compares them against the words in the string. The [split()](https://stackoverflow.com/questions/6181763/converting-a-string-to-a-list-of-words) function is used to split words.txt into a list of words, and [set()](https://www.dataquest.io/blog/how-to-remove-duplicates-from-a-python-list/#:~:text=Sets%20in%20Python%20are%20unordered,a%20set%20removes%20the%20duplicates.) is used to remove duplicates from the list. A [generator expression](https://chatgpt.com/share/6706c30b-ae3c-800f-a06a-a51b19853176) is used to iterate over the contents of both the newly created list of words and the string, in order to count the number of English words within the string. This is efficient for handling large datasets without loading them all into memory at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid English words: 34.99%\n"
     ]
    }
   ],
   "source": [
    "# Assign the path to the words file to a variable \n",
    "wordsFile = r'..\\docs\\english_words\\words.txt'\n",
    "\n",
    "# Read the list of English words from the file, creating a set of english words\n",
    "with open(wordsFile, 'r') as file:\n",
    "    englishWords = set(file.read().split())\n",
    "\n",
    "# Split the extended string into individual words\n",
    "wordsInString = generatedString.split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Call Method and Calculate English Word Percentage\n",
    "To test the functionality of the `wordPercentage` method to see if it calculates the percentage of English words in the 10,000 character string, both the words.txt file and the string are passed into the `wordPercentage` method, which then returns the English word percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of English words. The generator yields 1 for every word found in the set of English words.\n",
    "validWordCount = sum(1 for word in wordsInString if word in englishWords)\n",
    "\n",
    "# Calculate the percentage of valid English words\n",
    "totalWords = len(wordsInString)\n",
    "percentage = (validWordCount / totalWords) * 100\n",
    "\n",
    "# Print the percentage of valid English words\n",
    "print(f\"Percentage of valid English words: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Exporting Model as JSON\n",
    "## Step 1: Creating Method to Convert Model to JSON File\n",
    "A simple method named `convertModelToJSON` is used to create a JSON file using the [json.dump()](https://www.geeksforgeeks.org/convert-python-list-to-json/) function, which is ideal for converting lists to JSON files. In this case, it will be used to convert the trigram model, which is in list format, into the required JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertModelToJSON(trigramModel):\n",
    "    # Export the trigram model as a JSON file\n",
    "    with open('trigrams.json', 'w') as file:\n",
    "        json.dump(trigramModel, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Export the trigram model as a JSON file\n",
    "The trigram model which was created in Task 1 is passed in as an argument to `convertModelToJSON`, exporting the model as a JSON file as well as testing the functionality of the `convertModelToJSON` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the trigram model to a JSON file\n",
    "convertModelToJSON(trigramModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
