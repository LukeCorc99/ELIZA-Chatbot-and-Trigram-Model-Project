{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third-Order Letter Approximation Model Tasks\n",
    "### By Luke Corcoran\n",
    "### G00410404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary imports\n",
    "\n",
    "import os # For file operations\n",
    "import collections # For counting characters in files and creating a dictionary\n",
    "import random # For selecting random items from lists\n",
    "import json # For exporting model as a JSON file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Third-Order Letter Approximation Model\n",
    "### Step 1: Create method to format text files\n",
    "\n",
    "The `formatFiles` method is used to process text files in a folder to count how often certain characters appear. The [Counter() function](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) in Python's 'collections' module is used to keep track of character counts across all files. It then goes through each file in the folder using the [listdir() function in the 'os' module](https://pytutorial.com/python-using-oslistdir-to-list-files-in-a-directory/), checking if it ends with .txt and joining the file name and the directory path together using another function from the 'os' module, [path.join()](https://www.geeksforgeeks.org/python-os-path-join-method/), in order to access the file via the file path.\n",
    "\n",
    "For each text file, it reads the content using UTF-8 encoding and converts everything to uppercase. It removes any characters not in the list and searches for specific start and end markers to extract the main content of the file, using both [find()](https://www.w3schools.com/python/ref_string_find.asp) and Python's [slicing function](https://www.w3schools.com/python/ref_func_slice.asp). If these markers are found, it keeps only the text between them. It counts the characters in this cleaned text using the Counter() function and adds these counts to the total. Finally, it prints out the total counts for each character and returns the cleaned files in a list.\n",
    "\n",
    "### Step 2: Process Text Files\n",
    "\n",
    "The `formatFiles` method's functionality is tested by passing through both the directory containing all the text files and a string containing all the characters to keep. All text files in the folder are processed, while keeping the characters A-Z, space, and period. After the `formatFiles` method is called and takes the specified directory and characters to keep as arguments, it then reads and formats the text files, and counts the frequency of each character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Third-Order Letter Approximation Model\n",
    "### Step 1: Initialize Variables and Prepare to Process Files\n",
    "Firstly, in order to store both the text file directory and the characters to keep from the text files, the variables `directory` and `keep` are initialised for later use. The [Counter() function](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) from Python's 'collections' module is used to keep track of character counts across all files, and a list `cleanedFiles` is made to store the cleaned content of each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the text files\n",
    "directory = r'..\\docs\\utf8_english_works'\n",
    "\n",
    "# The characters to keep (ASCII, full stops, spaces).\n",
    "keep = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ .'\n",
    "\n",
    "# Initialize a Counter to store the frequency of each character across all files\n",
    "totalCounts = collections.Counter()\n",
    "    \n",
    "# Initialize a list to store cleaned files\n",
    "cleanedFiles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read and Clean Text Files\n",
    "Then, a loop is made which iterates over each file in the folder using the [listdir() function in the 'os' module](https://pytutorial.com/python-using-oslistdir-to-list-files-in-a-directory/), checking if it ends with .txt and joining the file name and the directory path together using another function from the 'os' module, [path.join()](https://www.geeksforgeeks.org/python-os-path-join-method/), in order to access the file via the file path. For each text file, the content is read using UTF-8 encoding with the [open()](https://stackoverflow.com/questions/491921/unicode-utf-8-reading-and-writing-to-files-in-python#:~:text=So%20by%20adding%20encoding%3D',of%20everything%20done%20in%20Python.) function. The text is then converted to uppercase using the [upper()](https://www.programiz.com/python-programming/methods/string/upper) method. A [generator expression](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Generators_and_Comprehensions.html#:~:text=in%20Python%20code%3A-,Definition%3A,provided%20within%20the%20parenthetical%20statement.) is employed to filter and retain only the characters specified in the `keep` variable, and the [join()](https://discuss.python.org/t/quick-question-on-join/14756) method is used to merge these characters into a string. Finally, using the [append()](https://www.programiz.com/python-programming/methods/list/append) function, the cleaned file is appended to a list of cleaned files for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all files in the directory\n",
    "for fileName in os.listdir(directory):\n",
    "    if fileName.endswith('.txt'):\n",
    "        filePath = os.path.join(directory, fileName)\n",
    "            \n",
    "        # Open the file with UTF-8 encoding\n",
    "        with open(filePath, 'r', encoding='utf-8') as file:\n",
    "            # Read the whole file into a string.\n",
    "            english = file.read()\n",
    "\n",
    "            # Change everything to upper case.\n",
    "            english = english.upper()\n",
    "\n",
    "            # Remove unwanted characters.\n",
    "            cleaned = ''.join(c for c in english if c in keep)\n",
    "\n",
    "            # Append the cleaned file to the list of cleaned files\n",
    "            cleanedFiles.append(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract Main Content from Files and Initialise Word Counts\n",
    "In this step, a new loop is made which iterates over each cleaned file. Preamble and postamble is removed using both [find()](https://www.w3schools.com/python/ref_string_find.asp) and Python's [slicing function](https://www.w3schools.com/python/ref_func_slice.asp). If the specified start and end markers are found, it keeps only the text between them. It counts the characters in this cleaned text using the [Counter()](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) function and adds these counts to a total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each character\n",
    "for cleaned in cleanedFiles:\n",
    "    # Remove preamble and postamble.If find returns -1, the substring was not found.\n",
    "    start = cleaned.find('START OF THE PROJECT GUTENBERG EBOOK')\n",
    "    end = cleaned.find('END OF THE PROJECT GUTENBERG EBOOK')\n",
    "\n",
    "    # If the substrings are found, extract the main content.\n",
    "    if start != -1 and end != -1:\n",
    "        cleaned = cleaned[start:end]\n",
    "    else:\n",
    "        print(\"ERROR: Substrings not found in file:\", fileName)\n",
    "        \n",
    "    # Count the frequency of each character in the current file\n",
    "    counts = collections.Counter(cleaned)\n",
    "\n",
    "    # Update the total counts with the counts from the current file\n",
    "    totalCounts.update(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create List of Cleaned Files\n",
    "To demonstrate the program works so far, the frequency of each character is then printed using a loop that iterates over all the characters and their corresponding counts. The [items()](https://www.programiz.com/python-programming/methods/dictionary/items) function is used to retrieve the key-value pairs (characters and their counts) from `totalCounts`. The cleaned files are stored in a list called `cleanedList` so that they can be used to count the number of sequences in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'S': 136438\n",
      "'T': 193301\n",
      "'A': 171189\n",
      "'R': 122258\n",
      "' ': 442809\n",
      "'O': 159367\n",
      "'F': 46913\n",
      "'H': 136849\n",
      "'E': 265142\n",
      "'P': 36138\n",
      "'J': 2418\n",
      "'C': 49677\n",
      "'G': 43500\n",
      "'U': 60490\n",
      "'N': 147529\n",
      "'B': 33311\n",
      "'K': 16941\n",
      "'L': 87108\n",
      "'Y': 42416\n",
      "'I': 144493\n",
      "'M': 55608\n",
      "'D': 92967\n",
      "'W': 50034\n",
      "'.': 23533\n",
      "'V': 19577\n",
      "'X': 2706\n",
      "'Z': 1117\n",
      "'Q': 2769\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for char, count in totalCounts.items():\n",
    "    print(f\"'{char}': {count}\")\n",
    "\n",
    "# Store contents of cleaned files in a list in order to count the number of sequences later\n",
    "cleanedList = cleanedFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Creating Trigram Model\n",
    "Finally, using the [defaultdict()](https://www.geeksforgeeks.org/defaultdict-in-python/) function, a dictionary is initialised as the data structure to store the results; this is effective because dictionaries in Python use key-value pairs, which is perfect for storing each trigram as a key and its respective appearance count as a value.\n",
    "\n",
    "A new loop is made to iterate over each file's content and extract the trigrams that appear in each file by slicing the text from a particular index range using the [range()](https://www.w3schools.com/python/ref_func_range.asp)\n",
    " function, incrementing the count of each trigram in the dictionary as it goes. The total count for each trigram is arranged from highest to lowest using the [sorted()](https://www.freecodecamp.org/news/sort-dictionary-by-value-in-python/#:~:text=reverse%20with%20a%20value%20of,sorted%20dictionary%20in%20descending%20order.&text=You%20can%20see%20the%20output,That's%20the%20default.) function. The final result is a sorted dictionary that holds the contents of the trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' TH', 50120), ('THE', 42657), ('HE ', 33535), ('ED ', 19427), ('AND', 19167), ('ND ', 18886), (' AN', 18522), ('ING', 16298), (' OF', 15054), ('NG ', 14348), (' TO', 14170), ('OF ', 13953), ('TO ', 12595), ('ER ', 12564), (' IN', 12352), ('AT ', 12066), ('IS ', 11072), ('IN ', 10547), (' HE', 10223), ('RE ', 9472)]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the trigram counts \n",
    "trigramCounts = collections.defaultdict(int) \n",
    "\n",
    "# Iterate over each cleaned file's content\n",
    "for cleaned in cleanedList:\n",
    "    # Iterate over the cleaned text to extract trigrams \n",
    "    for i in range(len(cleaned)): \n",
    "        trigram = cleaned[i:i+3] # Creates trigram by slicing the cleaned text from index i to i+3\n",
    "        trigramCounts[trigram] += 1 # Increment the count of the trigram in the dictionary\n",
    "\n",
    "    # Sort the trigram counts from highest to lowest\n",
    "    trigramModel = sorted(trigramCounts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Only displays the top 20 trigrams for brevity\n",
    "print(trigramModel[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Third Order Letter Approximation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize String beginning with TH\n",
    "To begin this task, a string beginning with TH is initialised, which will later be extended up to 10,000 characters. Trigrams beginning with TH and weights are found/created using [list comprehension](https://chatgpt.com/share/670583e8-8ca0-800f-bddd-9e8e27b62db1), with the weights being based off each trigram's reoccurence in the model. Both the trigrams beginning with TH along with their odds of being picked are then displayed using the [zip()](https://www.geeksforgeeks.org/zip-in-python/) function to merge the corresponding lists of trigrams and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams: | Odds of being chosen:\n",
      "THE       | 42657/67788\n",
      "THA       | 8266/67788\n",
      "TH        | 5632/67788\n",
      "THI       | 5589/67788\n",
      "THO       | 2667/67788\n",
      "THR       | 1349/67788\n",
      "THU       | 353/67788\n",
      "THY       | 279/67788\n",
      "THS       | 254/67788\n",
      "TH.       | 214/67788\n",
      "THT       | 100/67788\n",
      "THL       | 74/67788\n",
      "THW       | 65/67788\n",
      "THF       | 57/67788\n",
      "THD       | 51/67788\n",
      "THH       | 50/67788\n",
      "THM       | 33/67788\n",
      "THP       | 23/67788\n",
      "THC       | 18/67788\n",
      "THN       | 13/67788\n",
      "THB       | 12/67788\n",
      "THQ       | 12/67788\n",
      "THG       | 10/67788\n",
      "THK       | 5/67788\n",
      "THJ       | 3/67788\n",
      "THV       | 2/67788\n"
     ]
    }
   ],
   "source": [
    "# Use list comprehension to find trigrams that start with 'TH'\n",
    "thKeys = [key for key, value in trigramModel if key.startswith('TH')]\n",
    "\n",
    "# Create weights based on reoccurrence of trigrams in the model\n",
    "weights = [value for key, value in trigramModel if key in thKeys]\n",
    "\n",
    "# Calculate the total weight\n",
    "totalWeight = sum(weights)\n",
    "\n",
    "# Print trigrams and weights alongside each other as key-value pairs with total weight as denominator\n",
    "print(\"Trigrams: | Odds of being chosen:\")\n",
    "for key, weight in zip(thKeys, weights):\n",
    "    print(f\"{key}       | {weight}/{totalWeight}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialise 10,000 Character String with Random Trigram\n",
    "A trigram is then picked at random using the [random.choices()](https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb) function, [which bases its selection off weights](https://pynative.com/python-weighted-random-choices-with-probability/); with the more reoccuring trigrams having a higher chance of being selected such as 'THE', 'THA' etc. Using the [str()](https://www.w3schools.com/python/ref_func_str.asp)\n",
    " function the chosen trigram is then converted to a string, and the beginning of the 10,000 character string is initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen trigram to begin the string: THA\n"
     ]
    }
   ],
   "source": [
    "# Pick a trigram based on the weights, using [0] to extract the first element of the list \n",
    "chosenTrigram = random.choices(thKeys, weights)[0]\n",
    "\n",
    "# Convert the randomly chosen trigram to a string\n",
    "chosenTrigram = str(chosenTrigram)\n",
    "\n",
    "# Print the beginning of the 10,000 character string\n",
    "print(\"Chosen trigram to begin the string:\", chosenTrigram)\n",
    "\n",
    "# Initialize the generated string with the chosen trigram\n",
    "generatedString = chosenTrigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate More Characters to Add to the String\n",
    "Finally, the string needs more characters added to it to reach a length of 10,000 characters. In order to do this, a loop is created that adds characters to the string. Python's [string slicing](https://pythonexamples.org/python-string-get-last-n-characters/) function is used to get the last two characters of the string. [List comprehension](https://chatgpt.com/share/670583e8-8ca0-800f-bddd-9e8e27b62db1) is then used to both find trigrams in the model that begin with these two characters and create weights based off their reoccurence, and the [random.choices()](https://www.w3schools.com/python/ref_random_choices.asp) function is used to randomly select one of the third letters of those trigrams based off their weights. For each third letter that is selected, it is added to the string until it reaches 10,000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until the string reaches the desired length (10,000 characters)\n",
    "while len(generatedString) < 10000:\n",
    "    # Get the last two characters of the current generated string\n",
    "    lastTwoChars = generatedString[-2:]\n",
    "        \n",
    "    # Use list comprehension to find trigams that start with the last two characters\n",
    "    possibleTrigrams = [key for key, value in trigramModel if key.startswith(lastTwoChars)]\n",
    "        \n",
    "    # Create weights based on reoccurrence of trigrams in the model\n",
    "    weights = [value for key, value in trigramModel if key in possibleTrigrams]\n",
    "        \n",
    "    # Pick a trigram based on the weights\n",
    "    chosenTrigram = random.choices(possibleTrigrams, weights)[0]\n",
    "        \n",
    "    # Add the third character of the chosen trigram to the generated string\n",
    "    generatedString += chosenTrigram[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Test #1: Check to see that the String is 10,000 Characters Long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Generated String (first 100 characters): THATIOUR LIFE DES OF LIT ANY WITHATO BRITHE AHATENTHEMEADAGENTSEMANIS OF THE IS PAN ALE HAT TO RES C\n"
     ]
    }
   ],
   "source": [
    "# Ensure the generated string is exactly 10,000 characters long\n",
    "if len(generatedString) == 10000:\n",
    "    # Print the first 100 characters for verification\n",
    "    print(\"Final Generated String (first 100 characters):\", generatedString[:100])\n",
    "else:\n",
    "    # Return the generated string with an error message\n",
    "    print(\"ERROR: The generated string is not 10,000 characters, it is only\", len(generatedString), \"characters long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Analyze Your Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Analyze Your Model\n",
    "\n",
    "### Step 1: Prepare English Words List and Split the Generated String\n",
    "To begin this task, the path to a file called words.txt, which contains every word in the English dictionary, is stored in the variable `wordsFile`. The [split()](https://stackoverflow.com/questions/6181763/converting-a-string-to-a-list-of-words) function is used to split the `words.txt` file into a list of individual words, and [set()](https://chatgpt.com/share/671c3805-17b0-800f-945a-29c947e9b23e) is used to remove duplicates, creating a complete set of English words. In order to split the 10,000 character string into substrings that could possibly be words for future comparison, the `split()` function is used once more, with the result being stored in `wordsInString`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the path to the words file to a variable \n",
    "wordsFile = r'..\\docs\\english_words\\words.txt'\n",
    "\n",
    "# Read the list of English words from the file, creating a set of english words\n",
    "with open(wordsFile, 'r') as file:\n",
    "    englishWords = set(file.read().split())\n",
    "\n",
    "# Split the extended string into individual substrings\n",
    "wordsInString = generatedString.split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the Percentage of English Words in the String\n",
    "To calculate the percentage of English words, a [generator expression](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Generators_and_Comprehensions.html#:~:text=in%20Python%20code%3A-,Definition%3A,provided%20within%20the%20parenthetical%20statement.) is used to iterate over the contents of both the English words list and the generated string, allowing us to count the number of actual English words in the generated string. The percentage of valid English words relative to the total number of words in the string is then calculated using basic math and the result is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid English words: 35.54%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of English words. The generator yields 1 for every word found in the set of English words.\n",
    "validWordCount = sum(1 for word in wordsInString if word in englishWords)\n",
    "\n",
    "# Calculate the percentage of valid English words\n",
    "totalWords = len(wordsInString)\n",
    "percentage = (validWordCount / totalWords) * 100\n",
    "\n",
    "# Print the percentage of valid English words\n",
    "print(f\"Percentage of valid English words: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Exporting Model as JSON\n",
    "### Step 1: Creating Method to Convert Model to JSON File\n",
    "A simple method named `convertModelToJSON` is used to create a JSON file using the [json.dump()](https://www.geeksforgeeks.org/convert-python-list-to-json/) function, which is ideal for converting lists to JSON files. In this case, it will be used to convert the trigram model, which is in list format, into the required JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertModelToJSON(trigramModel):\n",
    "    # Export the trigram model as a JSON file\n",
    "    with open('trigrams.json', 'w') as file:\n",
    "        json.dump(trigramModel, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Export the trigram model as a JSON file\n",
    "The trigram model which was created in Task 1 is passed in as an argument to `convertModelToJSON`, exporting the model as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the trigram model to a JSON file\n",
    "convertModelToJSON(trigramModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
